# 基础助手设置

## 助手名称

自定义助手的名称。

## 聊天模型

为助手选择聊天模型。如果未设置，将使用全局默认聊天模型。

## 温度

设置助手的温度。

温度是一个控制大型语言模型（LLM）输出随机性的参数。
较低的温度值使输出更集中和确定性，而较高的值使其更具创造性和多样性。

0.0 是最确定性的，大多数情况下使用 0.3~0.7。

::: tip
某些 AI 模型需要特定的推荐温度才能运行，特别是某些推理模型。

详情请参考该模型的官方说明。
:::

## Top P

设置助手的 Top-P 采样（核采样）。

Top P 是一个通过从累积概率超过 P 的最小词汇集合中进行选择来控制 LLM 输出多样性的参数。

较低的值（例如 0.5）使输出更集中，而较高的值（例如 0.9）允许更多样性。

通常你应该保持在 `1.0`，或者不要与温度同时更改。

## 上下文消息大小

控制将发送到 LLM 的最大消息数量。
例如，如果将其设置为 `10`，LLM 将只接收最后 10 条消息。

## 思维预算

控制 LLM 可用于推理的最大 token 数量。

* 0 表示禁用推理。
* 空白表示模型将自动决定预算。
* 其他数字表示 LLM 可用于推理的最大 token 数量。

::: warning
此功能仅适用于 Google Gemini 提供商，因为不同提供商的思维预算 API 设计不同。

如果您想自定义其他提供商的思维预算，可以通过 `自定义请求` 功能进行自定义。
:::