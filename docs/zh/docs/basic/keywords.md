# AI 常见术语解释（新手友好）

## 基本概念

### LLM (大型语言模型)
大型语言模型是经过海量文本数据训练的AI系统，能够理解和生成人类语言。

**简单解释：** 想象一个超级“语言大脑”，它阅读了互联网上大量的文章、书籍和对话。正因为如此，它能理解你说的话并给出合理的回复。常见的LLM包括GPT系列、Claude、Llama、Qwen、Gemini、DeepSeek等。

**日常例子：** 当你问ChatGPT“红烧肉怎么做？”时，它能根据所学的烹饪知识，给你一份完整的菜谱和步骤。

### API (应用程序编程接口)
应用程序编程接口是软件系统之间进行通信的桥梁。通过LLM API，应用程序可以向AI发送请求并获取响应。

**简单解释：** 把API想象成餐厅里的服务员。它负责把你的（应用程序的）点餐（请求）传达给厨房（AI服务器），再把做好的菜（AI响应）端回来给你。

**日常例子：** 当你在微信小程序中使用AI功能时，小程序就是通过API将你的问题发送到远端的AI服务器，然后显示返回的结果。

### API Key
API Key是访问AI服务的唯一标识和密钥，用于验证请求的合法性并记录使用情况。

**简单解释：** 这相当于你的会员卡号。服务提供商通过它知道是谁在使用服务，并进行相应的计费。

**日常例子：** 就像你使用健身房会员卡一样，每次刷卡进入，系统都会记录你的使用情况。API Key也类似，每次你的应用程序调用AI服务时，都会使用这个密钥来验证身份。

### Token
在AI模型中，文本被分解成称为“Token”的小单元进行处理。

**简单解释：** 把Token看作是文本的“积木”。AI不是把文本作为一个整体句子来处理，而是将其拆分成更小的单元。在英文中，一个Token大约是4个字符或3/4个单词；在中文中，一个汉字通常就是一个Token。

**日常例子：**
- 英文句子“I love artificial intelligence”可能会被分成["I", "love", "art", "ificial", "intel", "ligence"]这样的Token
- 中文句子“我爱人工智能”会被分成["我", "爱", "人", "工", "智", "能"]这样的Token

### Prompt
Prompt是发送给AI的输入文本，用于引导AI生成特定的响应。

**简单解释：** 这就是你对AI说的话。它如何回应，很大程度上取决于你如何提问。就像你向一个人提问一样，一个好的问题更容易得到好的答案。

**日常例子：**
- 模糊的Prompt：“告诉我历史”（AI可能不知道要讲哪个时期的历史）
- 具体的Prompt：“请用简单的语言，向一个10岁的孩子解释中国唐朝的主要成就”（AI能给出更具针对性的回答）

Prompt分为：
- **System Prompt（系统提示）**：相当于给AI一个“角色设定”，比如“你是一位有耐心的，小学老师”
- **User Prompt（用户提示）**：用户实际发送的问题或指令

### Context Window (上下文窗口)
上下文窗口是指AI一次性能够处理的最大文本量，包括输入和输出。

**简单解释：** 想象成AI的“短期记忆”容量。上下文窗口越大，AI就能“记住”更长的对话历史，处理更复杂的问题。

**日常例子：** 如果上下文窗口是8K Token（约6000英文单词），你可以让AI分析一篇中等长度的文章；如果是32K Token，它就能处理小说的一个章节或一份长篇报告。

## 进阶概念

### Temperature (温度)
温度控制AI响应的随机性和创造性。

**简单解释：** 把它看作AI的“冒险指数”：
- **低温度（接近0）**：AI变得严谨保守，回答更确定、更重复。
- **高温度（接近1或更高）**：AI变得更有创造力，生成多样化、有时出人意料的回答。

**日常例子：**
- 低温度适用于：数学问题、事实查询、代码生成
- 高温度适用于：创意写作、故事创作、头脑风暴

### Top-p (核采样)
控制AI在生成文本时考虑的词汇范围。

**简单解释：** 想象一下，当AI选择下一个词时，它不是从所有可能的词中随机挑选，而是只从概率最高的词汇子集中选择。p值决定了这个“子集”的大小。

**日常例子：** 如果top-p设置为0.9，那么在生成文本时，AI只会考虑那些概率加起来达到90%的词语选项，而忽略那些不太可能出现的词。

:::warning 注意
top-p和temperature是控制AI生成随机性的两个参数。通常情况下，只修改temperature即可。
:::

### Embedding (嵌入)

嵌入是将文本转换为数值向量的过程，这些向量能够捕捉文本的含义。

**简单解释：** 把文本转换成AI能理解的“数字坐标”。意思相近的词语在这个坐标系中会靠得很近。

**日常例子：** 在这个数字坐标系中，“快乐”和“喜悦”会非常接近，而“快乐”和“悲伤”则会相距很远。这使得AI能够理解文本的语义关系。

### Fine-tuning (微调)

微调是在特定数据集上进一步训练AI模型，使其更适合特定任务或领域。

**简单解释：** 相当于给一个通用AI进行“专业特训”。例如，医疗机构可以用医疗数据微调一个通用AI，使其更擅长回答医学问题。

**日常例子：** 想象一位英语老师（基础模型）接受了化学方面的专业培训（微调）。现在，他不仅懂英语，还特别擅长用英语解释化学概念。

### RAG (Retrieval Augmented Generation - 检索增强生成)

在AI生成响应之前，它会先从知识库中检索相关信息，以提高答案的准确性。

**简单解释：** 想象AI有一个“参考书架”。在回答问题前，它会先查阅相关资料，而不是仅仅依靠“记忆”。

**日常例子：** 当你问“2023年世界杯谁赢了？”时，标准AI可能会回答错误（因为其训练数据可能截止在2023年之前），而使用RAG技术的AI会先查询最新的数据库，然后给出正确答案。

### Function Call (函数调用)

允许AI以结构化格式输出数据，并触发特定的动作。

**简单解释：** 让AI不仅能回答问题，还能帮你完成具体的任务，比如发送邮件、查询天气或预订机票。

**日常例子：** 当你对AI助手说“提醒我明天早上9点的会议”时，它不仅仅回复“好的”，而是真的创建了一个日历提醒。

### MCP (Model Context Protocol - 模型上下文协议)

MCP是一个开放协议，它规范了应用程序向大型语言模型提供上下文的方式。你可以把MCP理解为AI应用的USB-C接口。
正如USB-C为设备连接各种外设和配件提供了标准化的方式，MCP也为AI模型连接不同的数据源和工具提供了标准化的方式。

**简单解释：** 想象一个大模型就像一个聪明的“大脑”，它可以处理文本、图像、音频、视频等各种内容类型。MCP就像它的四肢。大模型可以通过不同的MCP，实现各种能力，比如访问地图信息，从而更好地完成任务。

## 使用相关

### Rate Limit (速率限制)

API提供商对使用频率施加的限制，通常表示为“每分钟请求数”或“每天请求数”。

**简单解释：** 类似于高速公路上的限速，防止单个用户占用过多资源。

**日常例子：** 某个AI服务可能规定免费用户每分钟最多发送5个请求。如果超出，就需要等待或升级到付费计划。

### Billing (计费)

AI服务的收费方式，通常根据使用量进行计费。

**简单解释：** 类似于手机套餐的计费，可能会根据使用量（流量）进行收费。

**日常例子：** OpenAI可能会根据处理的Token数量收费，例如每千个输入Token收费0.01美元，每千个输出Token收费0.03美元。

### Request (请求)

发送给AI服务的数据包，包含问题、参数和认证信息。

**简单解释：** 相当于你发给AI的“信件”，里面包含了你的问题和一些必要的信息。

**日常例子：** 当你在ChatGPT中输入一个问题时，后端会构建一个包含你的问题、对话历史和API Key的请求，并发送给OpenAI服务器。

### Response (响应)

AI返回的数据，包含生成的答案和元数据。

**简单解释：** AI对你请求的“回信”，里面包含了答案和一些你看不到的技术信息。

**日常例子：** 你向ChatGPT提问后，它返回的内容不仅包括你看到的答案，还有你没看到的后端信息，比如消耗了多少Token。

### Streaming (流式传输)

AI生成的内容实时返回，而不是等待所有内容生成完毕后一次性返回。

**简单解释：** 类似于视频流媒体，你可以边看边等待后续内容加载，而不用等整个视频下载完。

**日常例子：** 在ChatGPT中，你会看到AI的回答一个字一个字地出现，而不是等待很久然后突然出现完整的回答。这就是流式传输的效果。

### Model (模型)

指特定版本的AI语言模型，例如GPT-4、Claude-3.5、DeepSeek-V3.1等。

**简单解释：** 就像不同品牌和型号的汽车，每个AI模型都有其自身的特点和性能水平。

你可以访问 [LMArena](https://lmarena.ai/) 或 [LiveBench](https://livebench.ai/) 查看不同模型的性能排名。

虽然模型性能很重要，但更重要的是选择最适合你需求的模型。因为不同模型有不同的架构和参数量，它们的成本、输出速度、模型能力和指令遵循能力都不同。